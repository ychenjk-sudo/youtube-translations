# YouTube 视频翻译：John Schulman on dead ends, scaling RL, and building research institutions

## 视频元信息
- **视频ID**: 29BYxvvF1iM
- **视频链接**: https://www.youtube.com/watch?v=29BYxvvF1iM
- **发布时间**: 2025-12-17
- **频道**: Cursor
- **主题**: John Schulman 谈 OpenAI 早期历史、RL 研究的死胡同、AGI 预测以及新公司 Thinking Machines

---

## 核心观点
### 1. ChatGPT 的“速通”可能性
如果拥有现在的后训练（post-training）知识和数据构建方法，早在 2018-2019 年就可以用更少的算力和几名人才构建出 ChatGPT 3.5 级别的模型。通过更聪明的微调数据构建，可以显著提升计算效率。

### 2. 早期 OpenAI 的“草台班子”氛围
早期 OpenAI 更像是一个学术团体，由小团队根据个人兴趣驱动。虽然受 DeepMind 启发有大工程项目的理念，但实际上是小研究项目（1-3人）和大工程项目的混合体。

### 3. 被遗忘的死胡同：Universe 项目
早期有一个名为 Universe 的项目，试图建立一个包含所有游戏和网页任务的通用 RL 环境。虽然理念正确，但因过于超前（早了十年）和基础设施不完善而失败。机器人项目（Robotics）也是一个产品上的死胡同，但它帮助公司建立了大规模工程和研究的能力。

### 4. 追赶模式 vs 探索能力
新兴实验室容易陷入单纯追赶 SOTA（当前最佳水平）的模式。John 强调在 Thinking Machines 要避免这种情况，必须在追赶的同时建立探索性研究的“肌肉”和文化，否则后期很难补救。

### 5. 强化学习（RL）中的价值函数之谜
价值函数（Value Functions）在当前的 RLHF 和短视界任务中似乎作用不大，未能提供预期的方差减少（variance reduction）。但这可能只是暂时现象，未来可能会回归。

### 6. 持续学习：上下文 vs 参数微调
对于持续学习，短期内上下文学习（In-context learning）很难被超越，但长期来看，参数微调（如 LoRA）和权重更新会胜出，特别是对于需要大容量记忆的任务。

### 7. 生成器与验证器的协同训练
这是一个非常有前景的方向。随着模型推理和遵循指令能力的提升，它作为验证者（Verifier）的能力也会提升，从而为生成器（Generator）提供更好的学习信号，形成良性循环。

### 8. 工程师的时间预估偏差
工程师和研究人员倾向于严重低估项目耗时（通常建议乘以 3 倍）。参考自动驾驶的发展历程，AGI 的到来可能比许多乐观预测要晚，尽管 AI 的自我加速效应是一个变数。

### 9. 个人 AI 工作流
John 高频使用 AI（如 Cursor）进行编程、文献搜索和写作反馈。他认为现在的研究中，利用 LLM 进行文献调研和代码辅助已成为常态，但对于核心研究代码，逐行理解仍然至关重要。

### 10. Thinking Machines 与 Tinker
John 的新公司 Thinking Machines 推出了 Tinker，这是一个低层级的微调 API 服务。它允许开发者使用底层原语进行训练和采样，无需管理复杂的 GPU 基础设施，旨在服务于高水平的 ML 从业者。

---

## 完整中文翻译

### 如果回到过去“速通” ChatGPT
**主持人**：如果 OpenAI 的创始团队回到 2015、2016 年，想要“速通”（speedrun）构建 ChatGPT，他们能多快做到？瓶颈会在哪里？他们会采取哪些不同的举措？

**John Schulman**：是的，如果你想用更少的算力制造 ChatGPT，你是可以做到的，我们已经看到像 nanoGPT 这样的项目在做类似的事情。有时候用更多的算力做事更容易，但如果你加入更多巧妙的技巧，就能用更少的算力做到。我想我们本可以扩展得更快，或者如果我们知道回报会是那样的话，扩展是完全可能的。

如果你想早点做出来，如果你脑子里有完整的配方，你大概可以早很多构建出来。你可以组建一个大集群，预训练一个模型。鉴于我们现在对后训练（post-training）的所有了解，你可以通过更好地进行后训练来有效地大幅增加你的算力效能。所以，即使需要像 GPT-3 级别的模型才能创建一个好的少样本提示（few-shot prompted）聊天模型，如果你愿意做大量的微调，并且以巧妙的方式构建微调数据集，你可以让一个更小的模型变得相当不错。

**主持人**：你认为这需要多少人？在哪一年可以完成？需要多少 GPU？

**John Schulman**：如果我们假设拥有完全的后见之明……NanoGPT 只是由一个人编写的，运行在一台机器上，大概花了他半年时间。所以这至少是一个上限。当然这是在 H100 上，而我们早期只有 V100 之类的。但我认为我们可以凑齐几个 GPU 盒子。如果你有几个有才华的人工作一年左右，并且拥有完全的后见之明，我想你大概可以在 2018 或 2019 年就做出达到 ChatGPT 3.5 水平的东西。

实际上，这也是建立在其他人完成的预训练数据集和抓取工作之上的。所以我还没完全想透，但我会说，回到 2018 或 2019 年，几个人大概就能做出 GPT-3.5 水平的东西。也许未来我们会看到更极端的情况，比如演示场景（demo scene）版的 ChatGPT，就像一个文件训练整个东西，抓取网络，并在一天内完成训练。

### 早期 OpenAI：草台班子与死胡同
**主持人**：OpenAI 现在是世界上按市值计算最大的公司之一，但在早期，人们很容易忘记它是一个多么非正式、甚至有点“杂牌军”（ragtag）的团体。你同意这个前提吗？能不能帮我们描绘一下早期 OpenAI 的样子？有没有什么早期的失败项目，是那种完全走进死胡同、现在大家都不怎么提的？

**John Schulman**：是的，早期确实更“杂牌军”，甚至有点像一个学术团体。当时有一堆不同的研究项目，大家根据自己的品味在做，人们以一两三人的小组形式工作，最终产出论文或博客文章。OpenAI 的前几年很有这种味道。

当然，我们也一直有“大项目”的想法，认为相比学术界，我们可以通过做严肃的工程和组建更大的团队走得更远。我们也受到了 DeepMind 的影响，他们在很大程度上通过 AlphaGo 等项目开创了这种工作方式。所以公司是这些小型研究项目和旨在集合众多研究员与工程师的大型项目的混合体。

并不是所有的项目都成功了。显然很多研究项目没得善终。甚至可以说，项目最终没有成为科技树主干的一部分才是常态。

说到不那么成功的大项目，早期有一个叫 Universe 的项目。当时的想法是创建许多不同的 RL（强化学习）环境，建立一个大数据集，把它们放在一起。如果我们能在所有环境上联合训练，就能泛化到其他事物，得到一个通用的 RL 智能体。我们打算收集大量的视频游戏和网页导航任务。

有趣的是，我认为这是一个深刻正确的想法，但它太超前了，可能早了十年。当时缺少很多先决条件。人们聚在一起建立了这个系统并开始做实验，但整个系统非常笨重，对 RL 实验很不友好。而且因为我们是从头开始训练模型，这些模型并不能很好地泛化。所以当时它是失败的。

后来我们通过缩小范围获得了更多进展。我后来领导了强化学习研究团队几年，我们仍然致力于视频游戏环境的集合，但我们不再试图创建一个包含“电脑前能做的任何事”的大数据集，而是专注于模拟视频游戏。这最终变得更容易处理。

那是其中一个不成功的项目。还有像机器人（Robotics）项目，对公司来说最终也是某种死胡同，但从长远来看，它通过建立做大工程项目和研究项目的能力，以及培训大量人员，还是有用的。

### 研究管理的艺术
**主持人**：你会如何描述理想的研究管理者？这是一个奇怪的角色，因为 ML 领域的“大科学”越来越多，团队越来越大，需要更多的协调。

**John Schulman**：这是一个很难的问题，因为我见过人们采取非常不同的方法并取得成功。而且领域也在变化，这可能是一个非平稳问题（non-stationary problem）。七八年前行得通的方法现在可能不适用了。

我见过一种模式，小组负责人非常亲力亲为（hands-on），自己写很多代码，阅读下属的所有代码，给出非常详细的技术反馈。我也见过更放手（hands-off）的管理者，他们更多是充当参谋，提供职业建议而非详细的技术建议，保持大家开心和有动力，让人们做自己的事。

这两种模式在不同的地方都有效。如果你在做探索性研究，并且有经验丰富的人，放手让他们做自己的事是有意义的。但如果你更以目标为导向，或者人员经验较少，或者你想执行更具体的事情，那么管理者更亲力亲为、提供更多技术监督的模式可能更合理。

### 机构文化与追赶模式
**主持人**：关于研究机构，早期的 OpenAI、中后期的 OpenAI、Anthropic、Thinking Machines、Google，你会如何描述它们的差异？

**John Schulman**：这很难一概而论。但我确实看到早期 OpenAI 和现在的 Thinking Machines 有很多相似之处。我们有几个不同的项目在并行进行，我们仍在塑造公司的愿景，愿景将从这些项目的成型中浮现。

不同的是，现在的领域发展非常快，有其他公司在快速移动。所以有一种压力，要在做新东西的同时赶上当前的 SOTA（最先进水平）。而在 OpenAI 早期，虽然有 DeepMind，但并没有一个所有人都在竞争的清晰方向。那时候更像是“和平时期”，这导致了更多的探索性工作。

现在很多新成立的公司被迫处于“追赶模式”。我一直非常意识到这一点，并试图确保我们不仅仅是在追赶，我们还要建立做探索性研究的“肌肉”，探索那些不一定在主流路径上的新想法。因为如果你只是在追赶，以后就很难建立起那种探索性研究的肌肉和文化了。

### 强化学习的现状与未来
**主持人**：为什么价值函数（Value Functions）现在在 RL 中不流行了？

**John Schulman**：它们在人们目前进行 RL 的设置中似乎并没有太大帮助。例如在 RLHF（基于人类反馈的强化学习）和基于可验证奖励的 RL 中，时间视界（time horizon）相对较短。或者说，即使采样数万个 token 是一个很长的视界，但在当前的任务集合上，价值函数似乎并没有提供太多的方差减少（variance reduction）。

这有点难以解释原因。通常价值函数的主要目的是减少方差。但我预计价值函数在某个时候会卷土重来。

**主持人**：你认为我们如何解决持续学习（Continual Learning）？LoRA 会在其中发挥作用吗？

**John Schulman**：持续学习可能意味着几种不同的东西。有运动学习、情景记忆、程序性记忆等。我认为上下文（context）管理和长上下文能力将继续变得更好。我预计 LoRA（或参数微调）会叠加在此之上。

很难说我们需要什么，因为如果我们继续扩展模型，所有指标都会提升。但我预计权重更新（weight updates）在更长的时间视界上会胜出。上下文学习在非常短的视界内很难被击败，但在中间和长期范围内，参数微调会有帮助。

**主持人**：你担心泛化（Generalization）会成为通用 AI 的阻碍吗？

**John Schulman**：很难清晰地描述模型的泛化能力以及它们的样本效率与人类相比如何。在上下文学习中，模型的样本效率可以很高。但在某些类型的训练中，它们需要的数据比人类多得多。

人类经过进化的优化，可以在 80 年的时间跨度内运作，有很多自我纠正机制。如果给人类一个目标和动力，他们会非常足智多谋。而模型在做大块工作时往往更容易卡住。很难说这只是暂时的现象，还是需要很长时间才能达到人类的时间视界。

### 协同训练与多智能体
**主持人**：你认为联合训练模型（Co-training）会变得更流行吗？比如生成器和验证器一起训练？

**John Schulman**：是的，我认为联合训练生成器和验证器非常有意义。理论上你会得到某种自我提升。如果一个模型在验证过程中进行推理和遵循指令，你用它来为生成模型提供学习信号，那么随着模型在推理和遵循指令方面变得更好，它也会成为一个更好的验证者，这就形成了一个良性循环。

我也很喜欢多智能体训练或博弈的想法。设置零和博弈或多人博弈，可以给你一个自动的课程（curriculum）。因为如果你的对手是你自己的副本，随着你变强，对手也变强。理论计算机科学中也有理由支持这一点，比如通过计算成本低廉的过程（如裁判）创造激励，使得博弈的均衡点涉及解决一个非常难的问题。

### 个人 AI 使用习惯
**主持人**：你个人如何使用 AI？

**John Schulman**：我大量使用 AI 进行编程，我用 Cursor 和 Cloud Code。我会打开很多聊天窗口，向不同的模型提问。

我也在研究中大量使用模型。如果我现在有一个想法，我会向 GPT-5 Pro 抛出一堆问题，让它帮我做文献搜索。或者如果我有一个模糊的想法，我会写一两段话，让模型帮我充实它。文献搜索能力非常有用，找开源库也容易多了。

我也用它们来获得写作反馈。通常我会自己做大部分思考，但会用聊天模型作为我的第一轮反馈。

### AGI 时间线与预测偏差
**主持人**：关于 AGI 的时间线，工程师和研究人员似乎总是低估项目所需的时间。你认为这是一个合理的批评吗？

**John Schulman**：我同意存在低估时间线的持续偏差，也许是 2 到 3 倍。使用这个启发式方法，认为 AGI 会比人们的预测更远一点是合理的。最类似的类比可能是自动驾驶汽车，它比人们预期的要花更长的时间。

另一方面，AI 加速自身发展的正反馈循环可能会违背直觉。所以也有理由相信时间线会很短。这其中有很多不确定性。

### Thinking Machines 与 Tinker
**主持人**：你和 Thinking Machines 发布了 Tinker。它是什么？是给谁用的？

**John Schulman**：Tinker 是一个低层级的微调 API。它为你提供了一小组用于训练和采样的低级原语，让你能够表达几乎所有你想要的后训练算法，而无需担心 GPU、加速器或分布式系统的问题。

它是一个服务，抽象出了我们认为合适的层级。目前它是为那些在 ML 方面相当成熟、想要使用低级原语的人准备的。你可以通过编写 Python 脚本来编写训练代码，而不需要安装一堆东西在 GPU 上运行。

**主持人**：你的野心是让下一家由研究人员创办的公司直接建立在 Tinker 之上吗？

**John Schulman**：是的，我希望很多公司能够直接基于 Tinker 构建，而不是开发自己的基础设施。我们也会不断改进 Tinker，增加更多模型功能，如多模态输入输出，并支持更大规模的任务。

**主持人**：谢谢你，John。
**John Schulman**：谢谢邀请。

---
**翻译说明**：
- 翻译基于视频英文字幕逐字稿。
- "Thinking Machines" 和 "Tinker" 保留英文原名，分别为公司名和产品名。
- "Speedrush" 译为“速通”，"Rag tag" 译为“草台班子/杂牌军”。
- 演讲中的口语化表达已转化为流畅的中文。
