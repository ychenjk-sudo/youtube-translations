# YouTube 视频翻译：Jim Fan on Nvidia's Embodied AI Lab and Jensen Huang's Prediction that All Robots will be Autonomous

## 视频元信息
- **视频ID**: yMGGpMyW_vw
- **视频链接**: https://www.youtube.com/watch?v=yMGGpMyW_vw
- **发布时间**: 2024-09-17
- **频道**: Sequoia Capital（红杉资本）
- **时长**: 49 分钟 14 秒
- **主题**: Nvidia 具身智能 GEAR 实验室负责人 Jim Fan 访谈
- **嘉宾**: Jim Fan（Nvidia GEAR 实验室负责人）

---

## 核心观点

### 1. GEAR 实验室的使命与 Project GR00T
Jim Fan 领导的 GEAR (Generalist Embodied Agent Research) 团队致力于构建具身智能的基础模型。他们的核心项目 Project GR00T 旨在为人形机器人打造通用的 AI 大脑。团队的双重使命涵盖了物理世界的机器人和虚拟世界的游戏智能体。

### 2. 机器人的 "GPT-3 时刻"
Jim 预测在未来 2-3 年内，机器人领域将迎来类似 NLP 领域的 "GPT-3 时刻"。这意味着模型将在低层运动控制（System 1）上实现泛化，能够理解并执行抽象指令（如“打开”不同物体），而不仅仅是死记硬背特定的动作轨迹。

### 3. 具身智能的三元数据策略
为解决机器人训练的数据瓶颈，Jim 提出了三种数据的结合策略：
1.  **Internet-scale data (互联网规模数据)**：提供常识和高层规划能力，但缺乏动作标签。
2.  **Simulation data (仿真数据)**：通过 Nvidia 的仿真工具生成无限、带有动作标签的数据，速度可达实时的 10,000 倍。
3.  **Real-world robot data (真实世界机器人数据)**：通过遥操作收集，虽然昂贵且稀缺，但能弥补仿真与现实的差距 (Sim-to-Real gap)。

### 4. 仿真作为核心优势
Nvidia 从图形学起家，拥有强大的物理仿真和渲染能力（Isaac Sim）。利用 GPU 加速，他们可以在短时间内生成海量合成数据，这是 Nvidia 区别于其他依赖纯真实世界数据公司的核心竞争优势。

### 5. System 1 (直觉) 与 System 2 (推理) 的融合
机器人控制分为 System 1（快速、无意识的运动控制，如抓杯子）和 System 2（慢速、深思熟虑的规划，如 LLM 推理）。目前的挑战是如何将高频的 System 1 (1000Hz) 与低频的 System 2 (1Hz) 有效结合，可能采用级联或单一模型架构。

### 6. 优先发展人形机器人 (Humanoids)
选择人形机器人是因为人类社会的基础设施（餐厅、工厂、工具）都是为人类形态设计的。此外，互联网上充满了人类活动的视频数据，人形机器人最容易利用这些数据进行训练和迁移。

### 7. 通用派 (Generalist) vs 专用派 (Specialist)
Jim 坚信“通用派”路线。就像 ChatGPT 统一了 NLP 任务一样，未来的机器人模型也应该是一个通用的基础模型，可以泛化到不同的形态和任务，然后再针对特定场景进行微调（Specialized Generalist）。

### 8. Eureka 与 Dr. Eureka：LLM 驱动的强化学习
Jim 分享了 Eureka 项目，利用 LLM 编写奖励函数来训练机器人（如转笔）。后续的 Dr. Eureka 引入了域随机化 (Domain Randomization)，实现了从仿真到现实的零样本迁移（Zero-shot transfer），例如让机器狗在瑜伽球上保持平衡。

### 9. 虚拟世界与物理世界的统一
Jim 认为虚拟世界（游戏）和物理世界本质上只是参数不同的现实。通过“基础智能体 (Foundation Agent)”概念，未来的模型将能在技能、身体形态和现实环境（虚拟或物理）三个维度上实现大一统。

### 10. Jensen Huang 的预言
引用 Nvidia CEO 黄仁勋的观点：“所有移动的东西最终都将实现自主化 (Autonomous)。” 如果未来智能机器人的数量能像 iPhone 一样多，那么现在就必须开始构建相应的基础设施和计算平台。

### 11. 硬件成本的下降趋势
随着制造业成熟，人形机器人的成本有望降至汽车的价格水平（约 3 万美元）。硬件成本的指数级下降结合 AI 模型的突破，将加速机器人的普及。

---

## 完整中文翻译

**主持人**: 欢迎来到 Training Data 节目。今天我们邀请到了 Nvidia 高级研究科学家 Jim Fan。Jim 领导着 Nvidia 的具身智能体研究，肩负着跨越物理世界机器人和虚拟世界游戏智能体的双重使命。Jim 的团队负责 Project GR00T，也就是大家可能在今年 GTC 大会上看到的与 Jensen（黄仁勋）同台的 Nvidia 人形机器人。我们很兴奋能问 Jim 关于机器人的一切：为什么是现在？为什么是人形机器人？以及解锁机器人领域的 "GPT-3 时刻" 需要什么？欢迎来到 Training Data。

**Jim Fan**: 谢谢邀请。

**主持人**: 我们很兴奋今天能深入探讨你关于机器人和具身智能的分享。在此之前，你有一个迷人的个人故事。我想你是 OpenAI 的第一批实习生？能不能跟我们讲讲你的个人经历，你是如何走到今天的？

**Jim Fan**: 当然，我很乐意分享。回到 2016 年夏天，我的一些朋友说城里有个新的创业公司，你应该去看看。我想，反正我也没别的事做，因为我已经拿到了博士录取通知书，那个夏天正好空闲，所以我决定加入这家创业公司，结果它就是 OpenAI。
在 OpenAI 的时候，早在 2016 年我们就已经在讨论 AGI（通用人工智能）了。当时我的实习导师是 Andrej Karpathy 和 Ilya Sutskever。我们讨论并开展了一个叫 "World of Bits" 的项目。想法很简单：我们想建立一个 AI 智能体，它可以读取计算机屏幕像素，然后控制键盘和鼠标。如果你仔细想想，这个接口是非常通用的，我们在电脑上做的所有事情，比如回邮件、玩游戏、浏览网页，都可以在这个“像素到键盘鼠标”的接口中完成。这实际上是我在 OpenAI 对 AGI 的第一次尝试，也是我 AI 智能体之旅的第一章。

**主持人**: 我记得 World of Bits。实际上我不知道你参与了那个项目，真有趣。

**Jim Fan**: 是的，那是一个非常有趣的项目，它是 OpenAI Universe 计划的一部分，旨在将所有应用和游戏集成到一个框架中。

**主持人**: 你认为当时的突破点是什么？以及当时做智能体面临的挑战是什么？

**Jim Fan**: 当时我们主要使用强化学习 (Reinforcement Learning)。2016 年还没有 LLM (大语言模型)，没有 Transformer。问题是强化学习只能在特定任务上工作，无法泛化。我们不能给智能体任意的自然语言指令让它做任意的事情。所以当时它在我们设计的任务上能工作，但无法真正泛化。
这开启了我的下一章。我去了斯坦福大学，师从李飞飞 (Fei-Fei Li) 教授攻读博士学位，开始研究计算机视觉和具身智能。在斯坦福的 2016 到 2021 年间，我见证了飞飞领导的斯坦福视觉实验室从静态计算机视觉（识别图像和视频）向具身计算机视觉的转型，即智能体在交互式环境中学习感知并采取行动。这个环境可以是虚拟的仿真环境，也可以是物理世界。
博士毕业后，我加入了 Nvidia 并一直待到现在。我把博士期间的工作带到了 Nvidia，直到今天仍在研究具身智能。

**主持人**: 你负责 Nvidia 的具身智能计划，能不能简单介绍一下这意味着什么，以及你们希望达成什么目标？

**Jim Fan**: 我目前共同领导的团队叫 GEAR，代表 Generalist Embodied Agent Research（通用具身智能体研究）。用三个词总结我们的工作就是：我们生成行动 (We generate actions)。因为我们构建具身 AI 智能体，这些智能体在不同的世界中采取行动。如果在虚拟世界中行动，那就是游戏 AI 和仿真；如果在物理世界中行动，那就是机器人。
今年 3 月在 GTC 大会上，Jensen 的主题演讲中发布了 Project GR00T，这是 Nvidia 在构建人形机器人 Foundation Models（基础模型）上的登月计划。这基本上就是 GEAR 团队目前的重点。我们要为人形机器人，甚至更广泛的领域，构建 AI 大脑。

**主持人**: 你认为 Nvidia 在构建这个目标上的竞争优势是什么？

**Jim Fan**: 这是一个好问题。首先肯定是计算资源。所有的 Foundation Models 都需要大量的计算来扩展，我们相信 Scaling Law（缩放定律）。LLM 有缩放定律，但具身智能和机器人的缩放定律还有待研究，我们正在致力于此。
Nvidia 的第二个优势实际上是仿真 (Simulation)。在成为 AI 公司之前，Nvidia 是一家图形公司。Nvidia 在构建物理仿真、渲染以及 GPU 实时加速方面有多年的专业积累。我们在机器人构建方法中大量使用了仿真技术。

**主持人**: 仿真策略非常有趣。为什么你认为行业内大多数人仍然非常关注 Real-world robot data（真实世界数据），即相反的策略？

**Jim Fan**: 我认为我们需要所有类型的数据，单独依靠仿真或真实世界数据都是不够的。在 GEAR，我们将数据策略大致分为三类：
1.  **Internet-scale data (互联网规模数据)**：所有的文本和视频。
2.  **Simulation data (仿真数据)**：利用 Nvidia 的仿真工具生成大量合成数据。
3.  **Real-world robot data (真实世界机器人数据)**：通过遥操作机器人收集并记录的数据。
我相信一个成功的机器人策略将涉及这三种数据的有效利用、混合，并交付一个统一的解决方案。

**主持人**: 我们之前谈到数据是让机器人基础模型真正工作的关键瓶颈。能不能多谈谈你对此的信念，以及究竟需要什么样的数据才能突破这个问题？

**Jim Fan**: 这三种数据各有优缺点。
**Internet-scale data** 最具多样性，包含大量常识先验。例如，网上的视频大多是以人为中心的，因为人类喜欢自拍和记录生活。还有很多教学视频。我们可以利用这些来学习人类如何与物体交互，以及物体在不同情况下的表现。这为机器人基础模型提供了常识先验。但互联网数据没有“动作”——我们无法从互联网下载机器人的电机控制信号。
这就引出了第二部分：**Simulation data**。在仿真中，你可以拥有所有的动作数据，也能观察到动作在特定环境中的后果。仿真的优势在于它是无限的数据，数据量随算力扩展。投入的 GPU 越多，数据就越多。而且数据是超实时的。在真实机器人上收集数据受限于每天 24 小时，但在 GPU 加速的模拟器中，我们可以将时间加速 10,000 倍，从而获得极高的吞吐量。但仿真的弱点是，无论图形管线多好，永远存在 Sim-to-Real Gap（仿真到现实的差距）。物理特性会有所不同，视觉效果也不完全真实，而且仿真内容的多样性不如真实世界丰富。
最后是 **Real-world robot data**。这些数据没有 Sim-to-Real Gap，因为它们就是在真机上收集的。但收集成本极高，你需要雇人操作机器人，受限于原子世界的速度（每天 24 小时），这非常昂贵。
我们认为这三种数据具有互补的优势。成功的策略是结合它们的优势，消除它们的弱点。

**主持人**: 那些和 Jensen 一起在台上的可爱 GR00T 机器人，那是一个很酷的时刻。如果你展望 1 年、5 年、10 年，你认为你的团队会达成什么成就？

**Jim Fan**: 这是纯粹的推测，但我希望我们能在未来 2-3 年内看到机器人 Foundation Model 的研究突破，也就是我们所说的机器人的 "GPT-3 时刻"。
在那之后就比较难预测了，因为要让机器人进入人们的日常生活，除了技术还有很多因素。机器人需要价格亲民、可大规模生产，还需要硬件安全、隐私和法规，这些都需要更长时间。但我确实希望研究突破能在未来 2-3 年内到来。

**主持人**: 你认为 AI 机器人的 "GPT-3 时刻" 会是什么样子的？

**Jim Fan**: 我喜欢把机器人看作由两个系统组成：System 1 和 System 2。这来自《思考，快与慢》这本书。
**System 1** 是无意识且快速的低层运动控制。比如我抓这杯水，我不会去想每一毫秒指尖怎么移动。
**System 2** 是缓慢、深思熟虑的，更多是推理和规划，使用有意识的脑力。
我认为 "GPT-3 时刻" 将发生在 System 1 层面。我最喜欢的例子是动词“打开 (open)”。想一想“打开”这个词的复杂性：开门、开窗、开瓶盖、开手机，动作完全不同。但人类理解这些毫无困难。目前我们还没看到一个机器人模型能在低层运动控制上对这些动词进行泛化。我希望看到一个模型能理解这些动词的抽象含义，并泛化到各种对人类有意义的场景。我们还没看到这一点，但我对未来 2-3 年充满希望。

**主持人**: 那 System 2 的思考呢？你认为 LLM 领域的推理努力会关联到机器人领域吗？

**Jim Fan**: 绝对会。对于 System 2，我们已经看到了非常强大的模型能做推理、规划和编码。挑战在于如何将 System 2 模型与 System 1 集成。
对于机器人基础模型，是做一个单一的整体模型 (Monolithic model)，还是采用级联方法 (Cascaded approach) 让 System 2 和 System 1 分离并通信？这是一个开放问题。
整体模型更干净，只有一个 API。但很难控制，因为频率不同。System 2 可能以 1Hz（每秒一次决策）运行，而 System 1（如抓水杯的肌肉控制）可能需要 1000Hz。很难将两者编码在一个模型中。也许级联方法更好，但它们如何通信？是通过文本还是潜在变量 (Latent variables)？这还不清楚，是一个令人兴奋的新研究方向。

**主持人**: 你的直觉是我们会通过规模化 (Scale) 和 Transformer 在 System 1 上取得突破吗？还是需要别的？

**Jim Fan**: 我当然希望我描述的数据策略能带我们到达那里，因为我觉得我们还没有触及 Transformer 的极限。本质上，Transformer 输入 Token 输出 Token，Token 的质量决定了模型的质量。
对于机器人，一旦我们通过复杂的策略（互联网、仿真、真机）解决了数据问题，获得了高质量的动作数据，我们就可以将它们 Token 化并送入 Transformer 进行压缩。随着数据和模型规模的扩大，我们可能会看到涌现能力 (Emerging property)。我称之为具身智能的 Scaling Law，这仅仅是个开始。

**主持人**: 当我们实现这一目标时，你个人最兴奋的应用或用例是什么？

**Jim Fan**: 我们选择人形机器人作为主要研究载体有几个原因。
一是世界是围绕人类形态构建的。餐厅、工厂、医院、工具都是为人类设计的。原则上，足够好的人形硬件应该能完成任何合理人类能做的任务。虽然硬件还没到位，但我感觉未来 2-3 年人形机器人硬件生态系统会成熟，我们将拥有可负担的硬件。
一旦我们有了 GR00T 基础模型，能听懂语言指令并执行任务，我们将解锁巨大的经济价值。比如家务（洗衣、洗碗、做饭）、养老护理，以及在餐厅、医院、工厂的辅助工作。我希望这能在未来十年内实现。

**主持人**: 选择人形机器人还有其他原因吗？

**Jim Fan**: 还有更实际的原因，关于训练管线。网上有大量关于人类的数据，都是以人为中心的。人形机器人的形态最接近人类，这意味着用这些数据训练的模型更容易迁移到人形机器人上。
相比之下，网上有多少关于机械臂的视频？很少。但有无数人使用五指手操作物体的视频。所以我们先瞄准完全的通用性 (Full Generality)，然后再专精到机械臂等特定形态。

**主持人**: 你们现在是专注于人形机器人，还是也包括机械臂和机器狗？

**Jim Fan**: 对于 Project GR00T，我们目前更倾向于人形机器人。但我们构建的管线，包括仿真工具和真机工具，是足够通用的，未来可以适配其他平台。

**主持人**: 你多次使用了“通用 (General)”这个词。机器人领域有些人认为通用方法行不通，必须针对特定领域。你为什么选择通用方法？Richard Sutton 的 "Bitter Lesson"（苦涩的教训）在机器人领域也适用吗？

**Jim Fan**: 绝对适用。我想先谈谈 NLP 的成功故事。在 ChatGPT 之前，NLP 领域有很多针对不同应用（翻译、编码、数学）的专用模型。ChatGPT 出现后，统一了一切。
在 ChatGPT 之前我们称之为“专家 (Specialist)”，GPT-3 和 ChatGPT 是“通才 (Generalist)”。一旦有了通才，我们可以通过提示、蒸馏、微调将其变回特定任务的“专业通才 (Specialized Generalist)”。历史趋势表明，专业通才几乎总是比最初的专家强得多，而且更易于维护。
我认为机器人领域也会遵循同样的路径。2024 年大多数机器人应用仍处于专家阶段。Project GR00T 旨在构建通用基础模型。这在短期内更难，因为要解决更难的研究问题，但我们相信未来属于通才。

**主持人**: Nvidia 既拥有芯片又拥有模型，这很有趣。你认为 Nvidia 在优化 GR00T 方面能做什么？

**Jim Fan**: 在 3 月的 GTC 上，Jensen 发布了下一代边缘计算芯片 Jetson Thor，它是与 Project GR00T 共同发布的。我们的想法是为客户提供全栈统一的解决方案。从芯片层（Jetson Thor）到基础模型（Project GR00T），再到仿真和工具，这将成为人形机器人乃至智能机器人的计算平台。
我想引用 Jensen 的一句话：“所有移动的东西最终都将实现自主化 (Everything that moves will eventually be autonomous)。” 如果我们相信 10 年后智能机器人的数量会像 iPhone 一样多，那我们最好今天就开始构建。

**主持人**: 你们的研究中有没有什么特别的结果让你感到乐观？

**Jim Fan**: 有一个叫 **Eureka** 的工作。我们做了一个演示，训练一个五指机械手转笔。它的表现超越了人类（至少超越了我）。
我们使用 LLM 在 Nvidia 的 Isaac Sim API 中编写代码。LLM 输出奖励函数 (Reward Function) 的代码。奖励函数通常由人类专家设计，非常繁琐。Eureka 设计了一种算法，利用 LLM 自动化设计奖励函数，让机器人学会了转笔这样复杂的动作。这是一种通用技术，我们计划将其扩展到更多任务。

**主持人**: 为什么是现在？机器人领域似乎在过去一年重新升温。你认为这次有什么不同？

**Jim Fan**: 有几个关键因素：
1.  **机器人硬件**：自去年底以来，涌现了大量新硬件，如 Tesla Optimus、Boston Dynamics 等，硬件越来越强。
2.  **价格**：人形机器人的制造成本显著下降。以前 NASA 的机器人造价超过 150 万美元，现在有些公司能把价格做到 3 万美元左右，与汽车相当。随着量产，价格还会指数级下降。
3.  **基础模型**：System 2 的推理规划问题已经被前沿模型（GPT, Claude, Llama）很好地解决了。Eureka 项目正是利用了 LLM 的编码能力。多模态模型的进步也提升了机器视觉能力。

**主持人**: 我想转到虚拟世界的话题。你似乎对 Minecraft 和游戏很感兴趣，这与机器人有什么联系？

**Jim Fan**: 我的个人使命是解决具身智能。对于虚拟世界的具身智能体，那就是游戏和仿真。我也很喜欢玩游戏。
我做过几个游戏项目。第一个是 **MineDojo**，我们在 Minecraft 中开发通用智能体。我们收集了大量互联网数据（视频、Wiki、Reddit 论坛），训练模型玩 Minecraft。
第二个是 **Voyager**。GPT-4 出来后，我们利用它的编码能力作为行动。Voyager 编写代码与 Minecraft 交互。它有一个自我反思循环 (Self-reflection loop)，如果代码出错，它会根据反馈修正。写对的代码会被存入“技能库 (Skill Library)”。还有一个“自动课程 (Automated Curriculum)”，智能体知道自己懂什么不懂什么，从而提出合适的探索任务。

**主持人**: 谈谈那个课程 (Curriculum) 机制，这似乎是推理领域未解决的问题之一。

**Jim Fan**: Voyager 的自动课程展示了前沿模型的涌现能力。我们只给了一个高层目标“发现尽可能多的新物品”，没有具体指令。智能体能够通过编码、提示和技能库自我发现。这是一种涌现属性。

**主持人**: 为什么这么多研究是在虚拟世界中进行的？虚拟世界和物理世界的解决之道有何联系？

**Jim Fan**: 尽管游戏和机器人看起来不同，但它们共享许多原则。输入都是感知（视频流），输出都是动作（键盘鼠标 vs 电机控制）。都需要探索和强化学习。
区别在于机器人有 Sim-to-Real Gap。但我去年提出了 **Foundation Agent (基础智能体)** 的概念。我认为最终我们将拥有一个模型，能在三个轴上泛化：
1.  技能 (Skills)
2.  实施形态 (Embodiments)
3.  现实 (Realities - 虚拟或物理)
未来一个单一模型将能跨越虚拟和现实世界。

**主持人**: 你对游戏中的 AI 智能体有什么个人梦想？

**Jim Fan**: 我对两个方面很兴奋：
1.  **游戏内的智能 NPC**：现在的 NPC 都是脚本化的。如果 NPC 真正“活着”，有记忆，能改变剧情，那每个人的游戏体验都将不同，具有无限重玩价值。
2.  **游戏本身的生成**：结合 3D 生成、视频生成和语言智能体，游戏世界可以在你玩的过程中实时生成。这将是真正的开放式体验。

**主持人**: 虚拟世界的工作是为物理世界服务的吗？还是它本身就有价值？

**Jim Fan**: 我认为虚拟世界和物理世界最终只是同一轴线上不同的现实。
举个例子，**Domain Randomization (域随机化)**。我们在仿真中训练机器人，并行运行 10,000 个物理参数略有不同的仿真环境。如果一个智能体能掌握这 10,000 个不同的世界，那么真实的物理世界就只是第 10,001 个仿真环境。
这就是我们在 **Dr. Eureka**（Eureka 的后续工作）中所做的。我们利用 LLM 编写域随机化参数，训练出的策略能零样本迁移到现实世界。我们展示了一只机器狗在瑜伽球上行走并保持平衡，这甚至超越了真狗的表现（有人试过，他的狗做不到）。

**主持人**: 在虚拟世界领域，最近有很多基于 Transformer 的 3D 和视频模型。你认为 Transformer 是最终架构吗？还是需要根本性的突破？

**Jim Fan**: 对于机器人基础模型，我们还没触及 Transformer 的极限。目前的瓶颈是数据。一旦数据管线成熟，我们只需把 Token 喂给 Transformer。
当然，我也对 Transformer 的替代架构很感兴趣，比如 Mamba 和 Test-time training。它们在推理效率上很有前景，但还需要扩展到前沿模型的规模来验证。

**主持人**: 让我们来些快问快答。在具身智能之外，你对 AI 的什么最感兴趣？

**Jim Fan**: **视频生成 (Video Generation)**。我看作它是“世界模拟器 (World Simulator)”。我们从数据中学习物理和渲染。这能为具身智能提供数据驱动的仿真环境。

**主持人**: 长期来看（10年以上），你对 AI 最兴奋的是什么？

**Jim Fan**:
1.  **编码智能体 (Coding Agents)**：10 年后可能会有达到人类软件工程师水平的编码智能体，极大地加速开发。
2.  **机器人**：10 年后我们将拥有可靠性达到人类水平的人形机器人。我希望那时 Project GR00T 取得成功，机器人能帮我洗衣服——这是我一直的梦想。

**主持人**: 你在 AI 领域最崇拜谁？

**Jim Fan**: 我有太多英雄了。
-   **李飞飞 (Fei-Fei Li)**：我的博士导师。她教会了我“研究品味 (Research Taste)”。识别“解决什么问题”比“怎么解决”更重要。
-   **Andrej Karpathy**：伟大的教育家，他的代码写得像诗一样。
-   **Jensen Huang (黄仁勋)**：他非常关心 AI 研究，甚至懂很多模型的技术细节，我非常敬佩他。

**主持人**: 关于研究品味，你对 AI 创业者有什么建议？

**Jim Fan**: 现在的论文越来越易读且实用。我建议紧跟最新文献，并动手尝试开源工具。比如下载 Nvidia 的仿真工具，自己动手训练机器人。

**主持人**: 关于从 Jensen 身上学到的，对创业者有什么战术建议？

**Jim Fan**: **识别正确的问题**。Nvidia 押注人形机器人是因为相信这是未来。如果你相信 10 年后机器人会像 iPhone 一样多，那你最好今天就开始工作。要有长期的未来愿景。

**主持人**: 这是一个很好的结尾。Jim，非常感谢你的参与。

**Jim Fan**: 谢谢邀请。

---

**翻译说明**：
- 翻译基于视频英文字幕逐字稿
- 部分术语采用保留英文或音译的方式（如 GEAR、RL Foundation Models、Internet-scale data、Simulation data、Real-world robot data）
